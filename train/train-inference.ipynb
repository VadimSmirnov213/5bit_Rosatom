{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>article</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.JPG</td>\n",
       "      <td>0 0.495625 0.472500 0.556250 0.401667\\n</td>\n",
       "      <td>АМ116.06.00.901-03</td>\n",
       "      <td>АМ116.06.00.901-03</td>\n",
       "      <td>/home/user1/data/train Росатом/train/imgs/301.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299.jpg</td>\n",
       "      <td>0 0.477766 0.447012 0.378501 0.285247\\n</td>\n",
       "      <td>АМ116.06.00.901-03 1</td>\n",
       "      <td>АМ116.06.00.901-03</td>\n",
       "      <td>/home/user1/data/train Росатом/train/imgs/299.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>393.jpg</td>\n",
       "      <td>0 0.464706 0.504657 0.326797 0.446569\\n</td>\n",
       "      <td>АМ116.06.00.962 2</td>\n",
       "      <td>АМ116.06.00.962</td>\n",
       "      <td>/home/user1/data/train Росатом/train/imgs/393.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453.jpg</td>\n",
       "      <td>0 0.489542 0.528676 0.762092 0.348529\\n</td>\n",
       "      <td>АМ116.06.01.301 31</td>\n",
       "      <td>АМ116.06.01.301</td>\n",
       "      <td>/home/user1/data/train Росатом/train/imgs/453.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.JPG</td>\n",
       "      <td>0 0.476562 0.321573 0.703125 0.489919\\n</td>\n",
       "      <td>1391-30-0109 241</td>\n",
       "      <td>1391-30-0109</td>\n",
       "      <td>/home/user1/data/train Росатом/train/imgs/60.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_file                                    label                  text  \\\n",
       "0    301.JPG  0 0.495625 0.472500 0.556250 0.401667\\n    АМ116.06.00.901-03   \n",
       "1    299.jpg  0 0.477766 0.447012 0.378501 0.285247\\n  АМ116.06.00.901-03 1   \n",
       "2    393.jpg  0 0.464706 0.504657 0.326797 0.446569\\n     АМ116.06.00.962 2   \n",
       "3    453.jpg  0 0.489542 0.528676 0.762092 0.348529\\n    АМ116.06.01.301 31   \n",
       "4     60.JPG  0 0.476562 0.321573 0.703125 0.489919\\n      1391-30-0109 241   \n",
       "\n",
       "              article                                         image_path  \n",
       "0  АМ116.06.00.901-03  /home/user1/data/train Росатом/train/imgs/301.JPG  \n",
       "1  АМ116.06.00.901-03  /home/user1/data/train Росатом/train/imgs/299.jpg  \n",
       "2     АМ116.06.00.962  /home/user1/data/train Росатом/train/imgs/393.jpg  \n",
       "3     АМ116.06.01.301  /home/user1/data/train Росатом/train/imgs/453.jpg  \n",
       "4        1391-30-0109   /home/user1/data/train Росатом/train/imgs/60.JPG  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Этап I. Обучение модели [ правильнее сказать - пополнение базы данных ]\n",
    "\n",
    "#Получаем оригинальные данные из трейна\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_path = '/home/user1/data/train Росатом'\n",
    "\n",
    "# Путь к папкам\n",
    "images_dir = os.path.join(dir_path, 'train/imgs')  # Папка с изображениями\n",
    "labels_dir = os.path.join(dir_path, 'train/labels')  # Папка с разметками\n",
    "labels_text_dir = os.path.join(dir_path, \"train/labels_with_text\")\n",
    "\n",
    "# Список для хранения данных таблицы\n",
    "data = []\n",
    "\n",
    "# Обход папки с изображениями\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        label_path = os.path.join(labels_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "        label_text_path = os.path.join(labels_text_dir, os.path.splitext(image_file)[0] + '.bbox')\n",
    "\n",
    "        # Проверка наличия файла разметки\n",
    "        if os.path.exists(label_path):\n",
    "\n",
    "\n",
    "            # Чтение текстовых меток\n",
    "            if os.path.exists(label_text_path):\n",
    "                with open(label_text_path, 'r') as f:\n",
    "                    label_text = ''.join(f.readlines())\n",
    "                    label_text = label_text.replace('\\n', '')\n",
    "            else:\n",
    "                label_text = np.NaN\n",
    "\n",
    "\n",
    "            # Чтение текстовых меток\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    label = ''.join(f.readlines())\n",
    "            else:\n",
    "                label = np.NaN\n",
    "\n",
    "            # Добавление данных в таблицу\n",
    "            data.append([image_file, label, label_text])\n",
    "\n",
    "# Создание DataFrame с изображениями и текстовыми метками\n",
    "df = pd.DataFrame(data, columns=['image_file', 'label', 'text'])\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\"',''))\n",
    "df['article'] = df['text'].apply(lambda x: x.split(' ')[0]) #Разделяем артикул и номер\n",
    "df['image_path'] = images_dir+ '/' + df['image_file']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_309139/443440091.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  parts_df['text'] = parts_df['article'].apply(lambda x: x.replace('\"','')) + ' ' + parts_df['number']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>number</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"1391-30-0108 ТС1.1\"</td>\n",
       "      <td>75</td>\n",
       "      <td>1391-30-0108 ТС1.1 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"1391-30-0114 ТС1.1\"</td>\n",
       "      <td>43</td>\n",
       "      <td>1391-30-0114 ТС1.1 43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"1391-30-0115 ТС1.1\"</td>\n",
       "      <td>55</td>\n",
       "      <td>1391-30-0115 ТС1.1 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"1391-30-1145 ТС1.1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1391-30-1145 ТС1.1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"1391-30-1146 ТС1.1\"</td>\n",
       "      <td>223</td>\n",
       "      <td>1391-30-1146 ТС1.1 223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                article number                    text\n",
       "0  \"1391-30-0108 ТС1.1\"     75   1391-30-0108 ТС1.1 75\n",
       "1  \"1391-30-0114 ТС1.1\"     43   1391-30-0114 ТС1.1 43\n",
       "2  \"1391-30-0115 ТС1.1\"     55   1391-30-0115 ТС1.1 55\n",
       "3  \"1391-30-1145 ТС1.1\"      0    1391-30-1145 ТС1.1 0\n",
       "4  \"1391-30-1146 ТС1.1\"    223  1391-30-1146 ТС1.1 223"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем оригинальные данные из экселя, они нужны будут для формирования списка артикулов.\n",
    "\n",
    "def apply_to_number(x):\n",
    "    if x is not None:\n",
    "        return str(x).split('.')[0]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "data = pd.read_excel('./../details.xlsx')\n",
    "data['ПорядковыйНомер'] = data['ПорядковыйНомер'].apply(apply_to_number)\n",
    "parts_df = data[['ДетальАртикул', 'ПорядковыйНомер']]\n",
    "parts_df.columns = ['article', 'number']\n",
    "parts_df.head()\n",
    "parts_df['text'] = parts_df['article'].apply(lambda x: x.replace('\"','')) + ' ' + parts_df['number']\n",
    "parts_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В Данном ячейке описана логика работы OCR.\n",
    "# Изучив множество библиотек, обучив свои модели и поэксперементировав наша команда пришла к выводу\n",
    "# что лучшим решением по работе с такими данными будет PaddleOCR. \n",
    "#\n",
    "# Кроме этого он работает достаточно быстро и хорошо масштабируется, т.к. он не обучался только на тех данных\n",
    "# которые были представлены организаторами.\n",
    "\n",
    "from paddleocr import PaddleOCR\n",
    "import logging\n",
    "import time\n",
    "logging.getLogger(\"ppocr\").setLevel(logging.ERROR)\n",
    "\n",
    "# Инициализируем OCR       \n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=False, \n",
    "    lang='en',\n",
    "    ocr_version='PP-OCRv4',\n",
    "    use_space_char=True,\n",
    "    use_gpu=True,\n",
    "    enable_mkldnn=True,  \n",
    "    use_tensorrt=True, \n",
    "    enable_fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "def multi_angle_ocr(image, angles=[0, 45, 90, 135, 180, 225, 270, 315]):\n",
    "    \"\"\"Функция для распознавания текста на изображении с учетом различных углов\"\"\"\n",
    "    start_total = time.time()\n",
    "    \n",
    "    best_text = \"\"\n",
    "    max_confidence = 0\n",
    "    best_rotated = None\n",
    "    best_box = None\n",
    "    best_angle = 0\n",
    "\n",
    "    if image is None:\n",
    "        return best_text, best_rotated, best_box\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    max_dim = max(height, width)\n",
    "    if max_dim > 640:\n",
    "        scale = 640.0 / max_dim\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        image = cv2.resize(image, (new_width, new_height))\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "\n",
    "    for angle in angles:\n",
    "        \n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, rotation_matrix, (int(width), int(height)))\n",
    "        result = ocr.ocr(rotated, cls=False)\n",
    "        \n",
    "\n",
    "        if result[0]:\n",
    "            confidence = sum(line[1][1] for line in result[0])\n",
    "            if confidence > max_confidence:\n",
    "                max_confidence = confidence\n",
    "                best_text = \" \".join([line[1][0] for line in result[0]])\n",
    "                best_rotated = rotated\n",
    "                best_angle = angle\n",
    "\n",
    "                boxes = np.array([line[0] for line in result[0]])\n",
    "                min_x = np.min(boxes[:, :, 0])\n",
    "                min_y = np.min(boxes[:, :, 1])\n",
    "                max_x = np.max(boxes[:, :, 0])\n",
    "                max_y = np.max(boxes[:, :, 1])\n",
    "                \n",
    "                width_box = max_x - min_x\n",
    "                height_box = max_y - min_y\n",
    "                center_x = min_x + width_box/2\n",
    "                center_y = min_y + height_box/2\n",
    "                \n",
    "                \n",
    "                points = np.array([[center_x - width_box/2, center_y - height_box/2],\n",
    "                                 [center_x + width_box/2, center_y - height_box/2],\n",
    "                                 [center_x + width_box/2, center_y + height_box/2],\n",
    "                                 [center_x - width_box/2, center_y + height_box/2]])\n",
    "                \n",
    "                inv_rotation_matrix = cv2.getRotationMatrix2D(center, -best_angle, 1.0)\n",
    "                \n",
    "                ones = np.ones(shape=(len(points), 1))\n",
    "                points_ones = np.hstack([points, ones])\n",
    "                transformed_points = inv_rotation_matrix.dot(points_ones.T).T\n",
    "                \n",
    "                min_x = np.min(transformed_points[:, 0])\n",
    "                min_y = np.min(transformed_points[:, 1])\n",
    "                max_x = np.max(transformed_points[:, 0])\n",
    "                max_y = np.max(transformed_points[:, 1])\n",
    "                \n",
    "                width_box = max_x - min_x\n",
    "                height_box = max_y - min_y\n",
    "                center_x = min_x + width_box/2\n",
    "                center_y = min_y + height_box/2\n",
    "                \n",
    "                rel_center_x = center_x / width\n",
    "                rel_center_y = center_y / height\n",
    "                rel_width = width_box / width\n",
    "                rel_height = height_box / height\n",
    "                \n",
    "                best_box = [rel_center_x, rel_center_y, rel_width, rel_height]\n",
    "        \n",
    "    return best_text, best_rotated, best_box\n",
    "\n",
    "image = np.array(Image.open('./../test_data/459.jpg'))\n",
    "best_text, rotated_image, box = multi_angle_ocr(image)\n",
    "\n",
    "# В данной ячейке мы получаем векторные представления изображений и текста\n",
    "# для последующего их использования в модели сравнения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для сравнения текста и изображений мы используем модель CLIP.\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Функция для получения векторных представлений изображений и текста\n",
    "def get_clip_embeddings(image=None, text=None):\n",
    "    result = {}\n",
    "    with torch.no_grad():\n",
    "        if image is not None:\n",
    "            if isinstance(image, np.ndarray):\n",
    "                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if isinstance(image, str):\n",
    "                image = Image.open(image)\n",
    "                \n",
    "            inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "            result['image_embedding'] = image_features.cpu().numpy()\n",
    "        \n",
    "        if text is not None and isinstance(text, str):\n",
    "            inputs = processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "            text_features = model.get_text_features(**inputs)\n",
    "            result['text_embedding'] = text_features.cpu().numpy()\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем векторные представления для каждого изображения в тренировочном датасете\n",
    "# Также получаем векторные представления для каждого текста в тренировочном датасете? для того чтобы проводить множественное сравнение\n",
    "df['embeddings_image'] = df['image_path'].apply(lambda x: get_clip_embeddings(image=x)['image_embedding'])\n",
    "df['embeddings_text'] = df['text'].apply(lambda x: get_clip_embeddings(text=x)['text_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [07:28,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Применяем OCR к каждому изображению в тренировочном датасете\n",
    "# Получаем текст для каждого изображения\n",
    "df['ocr_text'] = ''\n",
    "for i,d in tqdm(df.iterrows()):\n",
    "    image_path = d['image_path']\n",
    "    image = cv2.imread(image_path)\n",
    "    best_text, rotated_image, boxes = multi_angle_ocr(image)\n",
    "    df.loc[i, 'ocr_text'] = best_text\n",
    "\n",
    "# Также получаем эмбеддинги для текста occr, чтобы у нас была возможность сравнивать релевантные текстовые представления\n",
    "df['ocr_text_embeddings'] = df['ocr_text'].apply(lambda x: get_clip_embeddings(text=x[:77])['text_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группируем детали по артикулу, считаем средние вектора. Они и будут являться основопологающими при выборе изображения.\n",
    "grouped = df.groupby('article').agg({\n",
    "    'image_file': lambda x: list(x),\n",
    "    'text': 'count', # Сохраняем список файлов\n",
    "    # 'ocr_text': lambda x: np.mean(x,axis=0),\n",
    "    'ocr_text_embeddings': lambda x: np.mean(x, axis=0),\n",
    "    'embeddings_image': lambda x: np.mean(x, axis=0),\n",
    "    'embeddings_text': lambda x: np.mean(x, axis=0)\n",
    "}).rename(columns={'text': 'count'})\n",
    "\n",
    "# Сохраняем результат для каждого класса. Таким образом можно сказать что grouped - это наша база данных.\n",
    "grouped.to_pickle('grouped.pkl')\n",
    "\n",
    "# На этом этап \"обучения\" модели можно считать завершенным.\n",
    "\n",
    "\n",
    "# Отличительной особенностью нашего решения является то, что нет необходимости множество раз дообучать модель.\n",
    "# Для точного предскаазния артикула в базу данных необходимо всего лишь одно изображения.\n",
    "# Если изображение не добавлять, то поиск будет осуществляться через OCR по тексту.\n",
    "\n",
    "# Кроме этого можно предсказывать изображения даже не по артикулу, а просто по фотографии, как и производить его поиск.\n",
    "\n",
    "# Если развить данную систему, добавив frontend-панель управлениия, то появится возможность динамически пополнять базу данных,\n",
    "# следить за ее состоянием, производить поиск как по артикулу, так и по самому предмету, либо же по фотографии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>count</th>\n",
       "      <th>ocr_text_embeddings</th>\n",
       "      <th>embeddings_image</th>\n",
       "      <th>embeddings_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1391-30-0109</th>\n",
       "      <td>[60.JPG, 81.JPG, 80.JPG, 59.JPG, 77.jpg, 70.JP...</td>\n",
       "      <td>15</td>\n",
       "      <td>[[0.017365314, 0.11561554, 0.07099361, 0.20430...</td>\n",
       "      <td>[[-0.24761134, -0.0367497, 0.051416826, 0.1916...</td>\n",
       "      <td>[[-0.025438841, 0.060193364, 0.06883027, 0.150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391-30-1139</th>\n",
       "      <td>[410.JPG, 362.JPG]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.08157718, 0.22039655, 0.011820257, 0.33380...</td>\n",
       "      <td>[[-0.1021947, 0.12941961, 0.0753935, -0.105946...</td>\n",
       "      <td>[[0.07487033, -0.05096645, 0.049642235, 0.1283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391-30-1140</th>\n",
       "      <td>[373.JPG, 346.JPG, 411.JPG]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.055068266, 0.09756765, 0.053187296, 0.2884...</td>\n",
       "      <td>[[-0.08799681, 0.21026927, 0.16012101, -0.1164...</td>\n",
       "      <td>[[0.06178923, -0.011043355, -0.021948034, 0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391-30-1151</th>\n",
       "      <td>[92.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.100430995, 0.24313453, 0.12627964, 0.12950...</td>\n",
       "      <td>[[-0.15982224, 0.053742856, 0.14010802, -0.014...</td>\n",
       "      <td>[[0.093301624, -0.049591593, 0.032554477, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753-30-0124</th>\n",
       "      <td>[413.JPG, 384.JPG]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.047549512, 0.18820047, 0.06791867, 0.1052...</td>\n",
       "      <td>[[-0.0197642, 0.18334894, 0.20647895, -0.00318...</td>\n",
       "      <td>[[-0.04941526, 0.23083419, 0.07926907, 0.16700...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     image_file  count  \\\n",
       "article                                                                  \n",
       "1391-30-0109  [60.JPG, 81.JPG, 80.JPG, 59.JPG, 77.jpg, 70.JP...     15   \n",
       "1391-30-1139                                 [410.JPG, 362.JPG]      2   \n",
       "1391-30-1140                        [373.JPG, 346.JPG, 411.JPG]      3   \n",
       "1391-30-1151                                           [92.jpg]      1   \n",
       "1753-30-0124                                 [413.JPG, 384.JPG]      2   \n",
       "\n",
       "                                            ocr_text_embeddings  \\\n",
       "article                                                           \n",
       "1391-30-0109  [[0.017365314, 0.11561554, 0.07099361, 0.20430...   \n",
       "1391-30-1139  [[0.08157718, 0.22039655, 0.011820257, 0.33380...   \n",
       "1391-30-1140  [[0.055068266, 0.09756765, 0.053187296, 0.2884...   \n",
       "1391-30-1151  [[0.100430995, 0.24313453, 0.12627964, 0.12950...   \n",
       "1753-30-0124  [[-0.047549512, 0.18820047, 0.06791867, 0.1052...   \n",
       "\n",
       "                                               embeddings_image  \\\n",
       "article                                                           \n",
       "1391-30-0109  [[-0.24761134, -0.0367497, 0.051416826, 0.1916...   \n",
       "1391-30-1139  [[-0.1021947, 0.12941961, 0.0753935, -0.105946...   \n",
       "1391-30-1140  [[-0.08799681, 0.21026927, 0.16012101, -0.1164...   \n",
       "1391-30-1151  [[-0.15982224, 0.053742856, 0.14010802, -0.014...   \n",
       "1753-30-0124  [[-0.0197642, 0.18334894, 0.20647895, -0.00318...   \n",
       "\n",
       "                                                embeddings_text  \n",
       "article                                                          \n",
       "1391-30-0109  [[-0.025438841, 0.060193364, 0.06883027, 0.150...  \n",
       "1391-30-1139  [[0.07487033, -0.05096645, 0.049642235, 0.1283...  \n",
       "1391-30-1140  [[0.06178923, -0.011043355, -0.021948034, 0.17...  \n",
       "1391-30-1151  [[0.093301624, -0.049591593, 0.032554477, 0.12...  \n",
       "1753-30-0124  [[-0.04941526, 0.23083419, 0.07926907, 0.16700...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Этап II. Инференс\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загружаем базу данных\n",
    "grouped = pd.read_pickle('grouped.pkl')\n",
    "\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': '1391-30-0109', 'text': '900832 181026', 'image_distance': 0.9257674, 'text_ocr_distance': 0.96897537, 'text_article_distance': 0.9646914, 'score': 0.9465146, 'bbox': [0.41640625, 0.6729166666666667, 0.4328125, 0.29583333333333345]}\n"
     ]
    }
   ],
   "source": [
    "# Код для предсказания артикула по изображению\n",
    "\n",
    "i = 16\n",
    "\n",
    "# Функция для вычисления косинусного сходства\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    # Ensure embeddings are 1D arrays\n",
    "    embedding1 = embedding1.flatten()\n",
    "    embedding2 = embedding2.flatten()\n",
    "    \n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    \n",
    "    # Calculate norms\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "# Функция для предсказания артикула по изображению  \n",
    "def get_image_article_text(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Применяем OCR, распознаем текст и bbox текста\n",
    "    best_text, rotated_image, box = multi_angle_ocr(image)\n",
    "\n",
    "    # \n",
    "    if rotated_image is not None:\n",
    "        image = rotated_image\n",
    "\n",
    "    # Получаем эмбеддинги изображения и найденного на картинке текста\n",
    "    image_embedding = get_clip_embeddings(image=image)['image_embedding']\n",
    "    text_embedding = get_clip_embeddings(text=best_text[:77])['text_embedding']\n",
    "\n",
    "    # Считаем схожесть входного изображения с изображениями (артикулами) в базе\n",
    "    image_distances = grouped['embeddings_image'].apply(lambda x: calculate_cosine_similarity(\n",
    "        image_embedding,\n",
    "        x \n",
    "    ))\n",
    "    # Считаем схожесть текста распознанного OCR с таким же распознанным OCR текстом для каждого артикула в базе\n",
    "    text_ocr_distances = grouped['ocr_text_embeddings'].apply(lambda x: calculate_cosine_similarity(\n",
    "        text_embedding,\n",
    "        x \n",
    "    ))\n",
    "\n",
    "    # Считаем схожесть текста распознанного OCR с оригинальным текстом артикула для каждого артикула в базе\n",
    "    text_article_distances = grouped['embeddings_text'].apply(lambda x: calculate_cosine_similarity(\n",
    "        text_embedding,\n",
    "        x \n",
    "    ))\n",
    "\n",
    "    # Все эти сравнения помогут нам с высокой точносью найти к какому артикулу пренадлежит данный текст. \n",
    "    # Кроме этого, сравнивая текстовые значения можно понять корректность нахождения номера изделия.\n",
    "\n",
    "    groups = pd.DataFrame(grouped.index, columns=['article'])\n",
    "    groups['image_distance'] = image_distances.values\n",
    "    groups['text_ocr_distance'] = text_ocr_distances.values\n",
    "    groups['text_article_distance'] = text_article_distances.values\n",
    "    # Считаем \"скор\" для каждого артикула. Больше всего основываемся на тексте\n",
    "    groups['score'] = groups['image_distance']*0.5+groups['text_ocr_distance']*0.3+groups['text_article_distance']*0.2\n",
    "    groups.sort_values(by='score', ascending=False, inplace=True)\n",
    "    # Берем артикул с наибольшим скором.\n",
    "    result = {'article': groups.iloc[0].article, 'text': best_text, 'image_distance': groups.iloc[0].image_distance, 'text_ocr_distance': groups.iloc[0].text_ocr_distance, 'text_article_distance': groups.iloc[0].text_article_distance, 'score': groups.iloc[0].score, 'bbox': box if box is not None else [0.5,0.5,0.5,0.5]}\n",
    "    return result\n",
    "\n",
    "result = get_image_article_text(image_path)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем метрики на датасете\n",
    "# Учитывая что все значения мбеддингов усредненные - можно считать что \\\n",
    "# На данном датасете можно валидироваться.\n",
    "\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "from Levenshtein import ratio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Функция для преобразования строки label в список bbox\n",
    "def parse_label(label):\n",
    "    try:\n",
    "        boxes = []\n",
    "        for item in label.split('\\n'):\n",
    "            if item:\n",
    "                _, x_center, y_center, width, height = map(float, item.split())\n",
    "                boxes.append([\n",
    "                    x_center - width / 2, y_center - height / 2,\n",
    "                    x_center + width / 2, y_center + height / 2\n",
    "                ])\n",
    "        return boxes\n",
    "    except:\n",
    "        raise Exception(\"Неправильный формат строки 'label'. Ожидается формат: '0 x_center y_center width height\\\\n...'\")\n",
    "\n",
    "# Функция для вычисления совокупного IoU для нескольких bbox\n",
    "def calculate_total_iou(predicted_boxes, true_boxes):\n",
    "    print(predicted_boxes, true_boxes)\n",
    "    predicted_polygons = [box(*pred_box) for pred_box in predicted_boxes]\n",
    "    true_polygons = [box(*true_box) for true_box in true_boxes]\n",
    "    predicted_union = unary_union(predicted_polygons)\n",
    "    true_union = unary_union(true_polygons)\n",
    "    intersection_area = predicted_union.intersection(true_union).area\n",
    "    union_area = predicted_union.union(true_union).area\n",
    "    total_iou = intersection_area / union_area if union_area != 0 else 0\n",
    "    return total_iou\n",
    "\n",
    "# Основная функция для расчета метрик\n",
    "def calc_metrics(ground_truth, submission):\n",
    "    ious = []\n",
    "    character_accuracies = []\n",
    "    complete_matches = []\n",
    "\n",
    "    ground_truth['text_is_notna'] = ground_truth['label_text'].notna()\n",
    "\n",
    "    for _, row in ground_truth.iterrows():\n",
    "        image_file = row['image_file']\n",
    "        sub_row = submission[submission['image_file'] == image_file]\n",
    "\n",
    "        if not sub_row.empty:\n",
    "            gt_boxes = parse_label(row['label'])\n",
    "            pred_boxes = parse_label(sub_row.iloc[0]['label'])\n",
    "            iou = calculate_total_iou(pred_boxes, gt_boxes)\n",
    "            ious.append(iou)\n",
    "\n",
    "            if row['text_is_notna']:\n",
    "                char_acc = ratio(row['label_text'], sub_row.iloc[0]['label_text'])\n",
    "                character_accuracies.append(char_acc)\n",
    "                complete_matches.append(row['label_text'] == sub_row.iloc[0]['label_text'])\n",
    "\n",
    "    # Заполняем отсутствующие значения\n",
    "    ious.extend([0] * (len(ground_truth) - len(ious)))\n",
    "    character_accuracies.extend([0] * (ground_truth['text_is_notna'].sum() - len(character_accuracies)))\n",
    "    complete_matches.extend([0] * (ground_truth['text_is_notna'].sum() - len(complete_matches)))\n",
    "\n",
    "    mean_iou = np.mean(ious)\n",
    "    mean_character_accuracy = np.mean(character_accuracies)\n",
    "    accuracy = np.mean(complete_matches)\n",
    "\n",
    "    return {\n",
    "        \"Средний IoU рамок\": mean_iou,\n",
    "        \"Средняя посимвольная точность текста\": mean_character_accuracy,\n",
    "        \"Точность абсолютно верного распознавания текста\": accuracy\n",
    "    }\n",
    "\n",
    "# Расчет финального балла\n",
    "def calc_score(metrics):\n",
    "    score = (metrics[\"Средний IoU рамок\"] * 0.05 +\n",
    "             metrics[\"Средняя посимвольная точность текста\"] * 0.65 +\n",
    "             metrics[\"Точность абсолютно верного распознавания текста\"] * 0.3)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.JPG</td>\n",
       "      <td>0 0.495625 0.472500 0.556250 0.401667\\n</td>\n",
       "      <td>\"АМ116.06.00.901-03\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299.jpg</td>\n",
       "      <td>0 0.477766 0.447012 0.378501 0.285247\\n</td>\n",
       "      <td>\"АМ116.06.00.901-03 1\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>393.jpg</td>\n",
       "      <td>0 0.464706 0.504657 0.326797 0.446569\\n</td>\n",
       "      <td>\"АМ116.06.00.962 2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453.jpg</td>\n",
       "      <td>0 0.489542 0.528676 0.762092 0.348529\\n</td>\n",
       "      <td>\"АМ116.06.01.301 31\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.JPG</td>\n",
       "      <td>0 0.476562 0.321573 0.703125 0.489919\\n</td>\n",
       "      <td>\"1391-30-0109 241\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>42.JPG</td>\n",
       "      <td>0 0.456771 0.376563 0.461458 0.103125\\n</td>\n",
       "      <td>\"195-30-1285 2668\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>443.JPG</td>\n",
       "      <td>0 0.506250 0.518623 0.751250 0.712190\\n</td>\n",
       "      <td>\"АМ116.06.00.902 2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>417.JPG</td>\n",
       "      <td>0 0.459167 0.519062 0.640000 0.236875\\n</td>\n",
       "      <td>\"АМ116.05.02.200 1\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>430.JPG</td>\n",
       "      <td>0 0.480208 0.497266 0.631250 0.202344\\n</td>\n",
       "      <td>\"АМ116.05.02.200 5\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>324.JPG</td>\n",
       "      <td>0 0.510625 0.525000 0.737500 0.601667\\n</td>\n",
       "      <td>\"АМ116.06.00.901\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_file                                    label  \\\n",
       "0      301.JPG  0 0.495625 0.472500 0.556250 0.401667\\n   \n",
       "1      299.jpg  0 0.477766 0.447012 0.378501 0.285247\\n   \n",
       "2      393.jpg  0 0.464706 0.504657 0.326797 0.446569\\n   \n",
       "3      453.jpg  0 0.489542 0.528676 0.762092 0.348529\\n   \n",
       "4       60.JPG  0 0.476562 0.321573 0.703125 0.489919\\n   \n",
       "..         ...                                      ...   \n",
       "247     42.JPG  0 0.456771 0.376563 0.461458 0.103125\\n   \n",
       "248    443.JPG  0 0.506250 0.518623 0.751250 0.712190\\n   \n",
       "249    417.JPG  0 0.459167 0.519062 0.640000 0.236875\\n   \n",
       "250    430.JPG  0 0.480208 0.497266 0.631250 0.202344\\n   \n",
       "251    324.JPG  0 0.510625 0.525000 0.737500 0.601667\\n   \n",
       "\n",
       "                 label_text  \n",
       "0      \"АМ116.06.00.901-03\"  \n",
       "1    \"АМ116.06.00.901-03 1\"  \n",
       "2       \"АМ116.06.00.962 2\"  \n",
       "3      \"АМ116.06.01.301 31\"  \n",
       "4        \"1391-30-0109 241\"  \n",
       "..                      ...  \n",
       "247      \"195-30-1285 2668\"  \n",
       "248     \"АМ116.06.00.902 2\"  \n",
       "249     \"АМ116.05.02.200 1\"  \n",
       "250     \"АМ116.05.02.200 5\"  \n",
       "251       \"АМ116.06.00.901\"  \n",
       "\n",
       "[252 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir = '/home/user1/data/train Росатом/train/imgs'\n",
    "labels_dir = '/home/user1/data/train Росатом/train/labels'\n",
    "labels_text_dir = '/home/user1/data/train Росатом/train/labels_with_text'\n",
    "\n",
    "data = []\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        label_path = os.path.join(labels_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "        label_text_path = os.path.join(labels_text_dir, os.path.splitext(image_file)[0] + '.bbox')\n",
    "\n",
    "        # Проверка наличия файла разметки\n",
    "        if os.path.exists(label_path):\n",
    "\n",
    "\n",
    "            # Чтение текстовых меток\n",
    "            if os.path.exists(label_text_path):\n",
    "                with open(label_text_path, 'r') as f:\n",
    "                    label_text = ''.join(f.readlines())\n",
    "                    label_text = label_text.replace('\\n', '')\n",
    "            else:\n",
    "                label_text = np.NaN\n",
    "\n",
    "\n",
    "            # Чтение текстовых меток\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    label = ''.join(f.readlines())\n",
    "            else:\n",
    "                label = np.NaN\n",
    "\n",
    "            # Добавление данных в таблицу\n",
    "            data.append([image_file, label, label_text])\n",
    "\n",
    "# Создание DataFrame с изображениями и текстовыми метками\n",
    "gt = pd.DataFrame(data, columns=['image_file', 'label', 'label_text'])\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [08:55<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "sub = []\n",
    "for image_file in tqdm(os.listdir(images_dir)):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        result = get_image_article_text(image_path)\n",
    "        label = '0 ' + ' '.join(map(str, result['bbox']))+'\\n'\n",
    "        if result['image_distance']>0.88:\n",
    "            text = '\"'+result[\"text\"]+'\"' if result['text_article_distance']>0.98 else '\"'+result[\"article\"]+' \"'\n",
    "        else:\n",
    "            text = result[\"text\"]\n",
    "        image_sub = {'image_file': image_file, 'label': label, 'label_text': text}\n",
    "        sub.append(image_sub)\n",
    "\n",
    "sub = pd.DataFrame(sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Средний IoU рамок': 0.5858090129419741,\n",
       " 'Средняя посимвольная точность текста': 0.8881395318693378,\n",
       " 'Точность абсолютно верного распознавания текста': 0.12698412698412698}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calc_metrics(gt, sub)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622999117287954"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = calc_score(metrics)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
